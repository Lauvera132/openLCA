{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c359fb",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This program performs analysis and visualization of openLCA results from an LCIA calculation, starting with an excel file export. This program assumes that you've already compiled an excel file of the unit processes exported from your openLCA database, with ISIC categories assigned to each process. This excel file should be named \"database_process_summary_added.xlsx\" with the corresponding file path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb1309a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e31a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and define variables\n",
    "# Change these variables to match your data\n",
    "\n",
    "impact_category_name = \"climate change - global warming potential (GWP100) (Nitrous Oxide, Methane, Carbon Dioxide)\"\n",
    "product_system_name = \"GeoH2 (85% mol H2; H2 Average Fugitive; CH4 Capture)\"\n",
    "product_system_name_simplified = \"GeoH2_85molH2_H2_AverageFugitive_CH4Capture\" # Simplified name file naming; Must not contain spaces or special characters\n",
    "GHG_intensity_impact_threshold = 0.05 # kg CO2 eq / kg H2 # Flows or processes with an impact lower than this threshold will be grouped into the \"Other\" category in the impact contribution plot.\n",
    "\n",
    "# LCA results file path and sheet names\n",
    "lca_results_file_path = r'C:\\Users\\laura\\OneDrive\\Documents\\UT_graduate\\WEG_graduate_research\\Hydrogen_fugitive_emissions_natural_h2\\openLCA_ecoinvent\\GeoH2__85__mol_H2__H2_Average_Fugitive__CH4_Capture_.xlsx'\n",
    "direct_impact_sheet_name = 'Direct impact contributions' #sheet name in the LCA results file\n",
    "impact_by_flow_sheet_name = 'Impact contributions by flow' #sheet name in the LCA results file\n",
    "\n",
    "# Database process summary file path; File must be named \"database_process_summary_added.xlsx\"\n",
    "database_process_summary_file_path = r'C:\\Users\\laura\\OneDrive\\Documents\\UT_graduate\\WEG_graduate_research\\Hydrogen_fugitive_emissions_natural_h2\\openLCA_ecoinvent\\openLCA\\database_process_summary_added.xlsx'\n",
    "\n",
    "# Define the output Excel file path\n",
    "output_excel_file_path = r'C:\\Users\\laura\\OneDrive\\Documents\\UT_graduate\\WEG_graduate_research\\Hydrogen_fugitive_emissions_natural_h2\\openLCA_ecoinvent' + f'\\\\{product_system_name_simplified}_data_export.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the \"output_excel_file_path\" contains special characters or spaces\n",
    "if re.search(r'[^\\w\\\\:.-]', output_excel_file_path):\n",
    "    print(\"The output Excel file path contains special characters or spaces.\")\n",
    "    print(\"Please update the 'product_system_name_simplified' variable to remove special characters or spaces.\")\n",
    "else:\n",
    "    print(\"The output Excel file path is valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d65bd4",
   "metadata": {},
   "source": [
    "# Read in LCA Results Excel File\n",
    "Read in LCA results impact by unit process and by flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b928d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the specified worksheet into a DataFrame\n",
    "df_process_impact = pd.read_excel(lca_results_file_path, sheet_name=direct_impact_sheet_name)\n",
    "df_flows_impact = pd.read_excel(lca_results_file_path, sheet_name=impact_by_flow_sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first column if it contains only empty values\n",
    "if df_process_impact.iloc[:, 0].isnull().all():\n",
    "    df_process_impact.drop(df_process_impact.columns[0], axis=1, inplace=True)\n",
    "if df_flows_impact.iloc[:, 0].isnull().all():\n",
    "    df_flows_impact.drop(df_flows_impact.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df_process_impact_transposed = df_process_impact.transpose()\n",
    "df_flows_impact_transposed = df_flows_impact.transpose()\n",
    "\n",
    "# Reset the index of the transposed DataFrame\n",
    "df_process_impact_transposed.reset_index(drop=True, inplace=True)\n",
    "df_flows_impact_transposed.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42484c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the column index of the target impact category in the transposed DataFrames\n",
    "process_column_index = df_process_impact_transposed.columns[df_process_impact_transposed.iloc[1] == impact_category_name].tolist()\n",
    "flows_column_index = df_flows_impact_transposed.columns[df_flows_impact_transposed.iloc[1] == impact_category_name].tolist()\n",
    "\n",
    "# If the column is found, retrieve its index; otherwise, return None\n",
    "process_column_index = process_column_index[0] if process_column_index else None\n",
    "flows_column_index = flows_column_index[0] if flows_column_index else None\n",
    "print(f\"Process column index: {process_column_index}\")\n",
    "print(f\"Flows column index: {flows_column_index}\")\n",
    "\n",
    "# Create a copy of transposed DataFrames with only specified columns\n",
    "process_columns_to_keep = [0, 1, 2, process_column_index]\n",
    "flows_columns_to_keep = [0, 1, 2, 3, 4, flows_column_index]\n",
    "df_process_impact_filtered = df_process_impact_transposed.iloc[:, process_columns_to_keep]\n",
    "df_flows_impact_filtered = df_flows_impact_transposed.iloc[:, flows_columns_to_keep]\n",
    "\n",
    "impact_category_uuid = df_process_impact_filtered.iloc[0, 3]\n",
    "impact_category_reference_unit = df_process_impact_filtered.iloc[2, 3]\n",
    "print(f\"Impact category UUID: {impact_category_uuid}\")\n",
    "print(f\"Impact category reference unit: {impact_category_reference_unit}\")\n",
    "\n",
    "# Remove unnecessary rows and rename the columns of the filtered DataFrames\n",
    "df_process_impact_filtered = df_process_impact_filtered.iloc[4:].reset_index(drop=True)\n",
    "df_process_impact_filtered.columns = ['Process_UUID', 'Process', 'Location', 'GWP100_Impact_Value_kg_CO2eq']\n",
    "df_flows_impact_filtered = df_flows_impact_filtered.iloc[4:].reset_index(drop=True)\n",
    "df_flows_impact_filtered.columns = ['Flow_UUID', 'Flow', 'Flow_Category', 'Flow_Sub-category', 'Flow_Unit', 'GWP100_Impact_Value_kg_CO2eq']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a48dd",
   "metadata": {},
   "source": [
    "# Read in OpenLCA Database Process Summary Excel File with ISIC Classifications\n",
    "Read in unique list of unit processes in openLCA database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the database process summary file\n",
    "database_process_df = pd.read_excel(database_process_summary_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split column \"ISIC_Category\" into multiple columns using \"/\" as the delimiter\n",
    "split_columns = database_process_df['ISIC_Category'].str.split('/', expand=True)\n",
    "\n",
    "# Rename the new columns for clarity\n",
    "split_columns.columns = ['ISIC_Category_Section', 'ISIC_Category_Division', 'ISIC_Category_Group', 'ISIC_Category_Class']\n",
    "\n",
    "# Add the split columns as additional columns to database_process_df\n",
    "database_process_df = pd.concat([database_process_df, split_columns], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19433fba",
   "metadata": {},
   "source": [
    "# Merge Database Process Summary DataFrame to LCA results Process Impact DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the database process summary DataFrame with the filtered process impact DataFrame\n",
    "merged_process_df = pd.merge(df_process_impact_filtered, database_process_df, on='Process_UUID', how='left')\n",
    "\n",
    "# Check if the \"Process\" column exists in both DataFrames after the merge\n",
    "if 'Process_x' in merged_process_df.columns and 'Process_y' in merged_process_df.columns:\n",
    "    # Check if the \"Process\" columns match in both DataFrames\n",
    "    if (merged_process_df['Process_x'] == merged_process_df['Process_y']).all():\n",
    "        # Drop one of the \"Process\" columns and rename the other to \"Process\"\n",
    "        merged_process_df.drop(columns=['Process_y'], inplace=True)\n",
    "        merged_process_df.rename(columns={'Process_x': 'Process'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Warning: Process columns do not match completely.\")\n",
    "else:\n",
    "    print(\"Error: Process columns are missing in the merged DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d64988",
   "metadata": {},
   "source": [
    "# Analyze DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GWP100 impact value to numeric, forcing errors to NaN\n",
    "merged_process_df['GWP100_Impact_Value_kg_CO2eq'] = pd.to_numeric(merged_process_df['GWP100_Impact_Value_kg_CO2eq'], errors='coerce')\n",
    "df_process_impact_filtered['GWP100_Impact_Value_kg_CO2eq'] = pd.to_numeric(df_process_impact_filtered['GWP100_Impact_Value_kg_CO2eq'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the GWP100 impact value column\n",
    "merged_process_df.dropna(subset=['GWP100_Impact_Value_kg_CO2eq'], inplace=True)\n",
    "df_flows_impact_filtered.dropna(subset=['GWP100_Impact_Value_kg_CO2eq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2648439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by \"Process\" and sum the GWP100 impact values, then sort\n",
    "grouped_process_df = merged_process_df.groupby('Process')['GWP100_Impact_Value_kg_CO2eq'].sum().reset_index()\n",
    "grouped_process_df.sort_values(by='GWP100_Impact_Value_kg_CO2eq', ascending=False, inplace=True)\n",
    "\n",
    "# Group the data by \"ISIC_Category_Section\" and sum the GWP100 impact values, then sort\n",
    "grouped_isic_df = merged_process_df.groupby('ISIC_Category_Section')['GWP100_Impact_Value_kg_CO2eq'].sum().reset_index()\n",
    "grouped_isic_df.sort_values(by='GWP100_Impact_Value_kg_CO2eq', ascending=False, inplace=True)\n",
    "\n",
    "# Group the data by \"Flow\" and sum the GWP100 impact values, then sort\n",
    "grouped_flows_df = df_flows_impact_filtered.groupby('Flow')['GWP100_Impact_Value_kg_CO2eq'].sum().reset_index()\n",
    "grouped_flows_df.sort_values(by='GWP100_Impact_Value_kg_CO2eq', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d5ac1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Create copies of the grouped DataFrames for \"Process\", \"ISIC_Category_Section\", and \"Flows\" to group the \"Other\" category separately\n",
    "grouped_process_other_df = grouped_process_df.copy()\n",
    "grouped_isic_other_df = grouped_isic_df.copy()\n",
    "grouped_flows_other_df = grouped_flows_df.copy()\n",
    "\n",
    "# Group \"Process\" with less than the \"GHG_Intensity_Impact_Threshold\" value into \"Other\" category\n",
    "grouped_process_other_df['Process'] = grouped_process_other_df['Process'].where(\n",
    "    grouped_process_other_df['GWP100_Impact_Value_kg_CO2eq'] >= GHG_intensity_impact_threshold, 'Other'\n",
    ")\n",
    "\n",
    "# Aggregate the \"Other\" group and sum the GWP100 impact values\n",
    "grouped_process_other_df = grouped_process_other_df.groupby('Process', as_index=False).sum().reset_index(drop=True)\n",
    "\n",
    "# Group \"ISIC_Category_Sections\" with less than the \"GHG_Intensity_Impact_Threshold\" value into \"Other\" category\n",
    "grouped_isic_other_df['ISIC_Category_Section'] = grouped_isic_other_df['ISIC_Category_Section'].where(\n",
    "    grouped_isic_other_df['GWP100_Impact_Value_kg_CO2eq'] >= GHG_intensity_impact_threshold, 'Other'\n",
    ")\n",
    "\n",
    "# Aggregate the \"Other\" group and sum the GWP100 impact values\n",
    "grouped_isic_other_df = grouped_isic_other_df.groupby('ISIC_Category_Section', as_index=False).sum().reset_index(drop=True)\n",
    "\n",
    "# Group \"Flows\" with less than the \"GHG_Intensity_Impact_Threshold\" value into \"Other\" category\n",
    "grouped_flows_other_df['Flow'] = grouped_flows_other_df['Flow'].where(\n",
    "    grouped_flows_other_df['GWP100_Impact_Value_kg_CO2eq'].astype(float) >= GHG_intensity_impact_threshold, 'Other'\n",
    ")\n",
    "\n",
    "# Aggregate the \"Other\" group and sum the GWP100 impact values\n",
    "grouped_flows_other_df = grouped_flows_other_df.groupby('Flow', as_index=False).sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af52208",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrames in descending order of GWP Impact Value, ensuring \"Other\" is always last\n",
    "grouped_process_other_df = grouped_process_other_df.sort_values(\n",
    "    by='GWP100_Impact_Value_kg_CO2eq', ascending=False\n",
    ").reset_index(drop=True)\n",
    "if 'Other' in grouped_process_other_df['Process'].values:\n",
    "    other_row = grouped_process_other_df[grouped_process_other_df['Process'] == 'Other']\n",
    "    grouped_process_other_df = grouped_process_other_df[grouped_process_other_df['Process'] != 'Other']\n",
    "    grouped_process_other_df = pd.concat([grouped_process_other_df, other_row], ignore_index=True)\n",
    "\n",
    "grouped_isic_other_df = grouped_isic_other_df.sort_values(\n",
    "    by='GWP100_Impact_Value_kg_CO2eq', ascending=False\n",
    ").reset_index(drop=True)\n",
    "if 'Other' in grouped_isic_other_df['ISIC_Category_Section'].values:\n",
    "    other_row = grouped_isic_other_df[grouped_isic_other_df['ISIC_Category_Section'] == 'Other']\n",
    "    grouped_isic_other_df = grouped_isic_other_df[grouped_isic_other_df['ISIC_Category_Section'] != 'Other']\n",
    "    grouped_isic_other_df = pd.concat([grouped_isic_other_df, other_row], ignore_index=True)\n",
    "\n",
    "grouped_flows_other_df = grouped_flows_other_df.sort_values(\n",
    "    by='GWP100_Impact_Value_kg_CO2eq', ascending=False\n",
    ").reset_index(drop=True)\n",
    "if 'Other' in grouped_flows_other_df['Flow'].values:\n",
    "    other_row = grouped_flows_other_df[grouped_flows_other_df['Flow'] == 'Other']\n",
    "    grouped_flows_other_df = grouped_flows_other_df[grouped_flows_other_df['Flow'] != 'Other']\n",
    "    grouped_flows_other_df = pd.concat([grouped_flows_other_df, other_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5107ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For think-cell plotting only, format data frames for Excel export\n",
    "# Create copies of the grouped DataFrames for think-cell plotting\n",
    "thinkcell_grouped_process_df = grouped_process_df.copy()\n",
    "thinkcell_grouped_process_other_df = grouped_process_other_df.copy()\n",
    "thinkcell_grouped_isic_df = grouped_isic_df.copy()\n",
    "thinkcell_grouped_isic_other_df = grouped_isic_other_df.copy()\n",
    "thinkcell_grouped_flows_df = grouped_flows_df.copy()\n",
    "thinkcell_grouped_flows_other_df = grouped_flows_other_df.copy()\n",
    "\n",
    "# Add a blank first row to each DataFrame for think-cell stacked bar chart plotting\n",
    "blank_row_process = pd.DataFrame([['', 0]], columns=thinkcell_grouped_process_df.columns)\n",
    "blank_row_isic = pd.DataFrame([['', 0]], columns=thinkcell_grouped_isic_df.columns)\n",
    "blank_row_flows = pd.DataFrame([['', 0]], columns=thinkcell_grouped_flows_df.columns)\n",
    "\n",
    "thinkcell_grouped_process_df = pd.concat([blank_row_process, thinkcell_grouped_process_df], ignore_index=True)\n",
    "thinkcell_grouped_process_other_df = pd.concat([blank_row_process, thinkcell_grouped_process_other_df], ignore_index=True)\n",
    "thinkcell_grouped_isic_df = pd.concat([blank_row_isic, thinkcell_grouped_isic_df], ignore_index=True)\n",
    "thinkcell_grouped_isic_other_df = pd.concat([blank_row_isic, thinkcell_grouped_isic_other_df], ignore_index=True)\n",
    "thinkcell_grouped_flows_df = pd.concat([blank_row_flows, thinkcell_grouped_flows_df], ignore_index=True)\n",
    "thinkcell_grouped_flows_other_df = pd.concat([blank_row_flows, thinkcell_grouped_flows_other_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c299193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the grouped DataFrames to separate sheets in the Excel file\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='xlsxwriter') as writer:\n",
    "    thinkcell_grouped_process_df.to_excel(writer, sheet_name='Grouped_Process', index=False)\n",
    "    thinkcell_grouped_process_other_df.to_excel(writer, sheet_name='Grouped_Process_Other', index=False)\n",
    "    thinkcell_grouped_isic_df.to_excel(writer, sheet_name='Grouped_ISIC', index=False)\n",
    "    thinkcell_grouped_isic_other_df.to_excel(writer, sheet_name='Grouped_ISIC_Other', index=False)\n",
    "    thinkcell_grouped_flows_df.to_excel(writer, sheet_name='Grouped_Flows', index=False)\n",
    "    thinkcell_grouped_flows_other_df.to_excel(writer, sheet_name='Grouped_Flows_Other', index=False)\n",
    "\n",
    "print(f\"Grouped data has been exported to {output_excel_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa065ed",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified horizontal bar plot with segments in descending order\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Sort the DataFrame by impact values in descending order\n",
    "grouped_process_other_df.sort_values(by='GWP100_Impact_Value_kg_CO2eq', ascending=False, inplace=True)\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "cumulative_width = 0\n",
    "bar_height = 0.3\n",
    "\n",
    "for i, row in grouped_process_other_df.iterrows():\n",
    "    process = row['Process']\n",
    "    value = row['GWP100_Impact_Value_kg_CO2eq']\n",
    "    plt.barh(\n",
    "        y=0,\n",
    "        width=value,\n",
    "        left=cumulative_width,\n",
    "        height=bar_height,\n",
    "        color=colors[i % len(colors)],\n",
    "        edgecolor='white',\n",
    "        linewidth=2,\n",
    "        label=process\n",
    "    )\n",
    "    # Add text for segments wide enough\n",
    "    if value > 0.05:\n",
    "        plt.text(\n",
    "            x=cumulative_width + value / 2,\n",
    "            y=0,\n",
    "            s=f'{value:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=12,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    cumulative_width += value\n",
    "\n",
    "# Add total at the end\n",
    "plt.text(\n",
    "    x=cumulative_width + 0.03 * cumulative_width,\n",
    "    y=0,\n",
    "    s=f'Total: {cumulative_width:.2f}',\n",
    "    va='center',\n",
    "    ha='left',\n",
    "    color='white',\n",
    "    fontsize=13,\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.xlabel('GWP100 Impact (kg CO2eq per kg H2)', fontsize=13, color='white')\n",
    "plt.title(f'{product_system_name_simplified} - by Process', fontsize=14, color='white', pad=15)\n",
    "plt.xticks(color='white', fontsize=11)\n",
    "plt.yticks([])\n",
    "\n",
    "plt.xlim(0, cumulative_width * 1.12)\n",
    "\n",
    "plt.legend(\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    "    ncol=1,\n",
    "    fontsize=11,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified horizontal bar plot with segments in descending order for grouped_isic_other_df\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Sort the DataFrame by impact values in descending order\n",
    "grouped_isic_other_df.sort_values(by='GWP100_Impact_Value_kg_CO2eq', ascending=False, inplace=True)\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "cumulative_width = 0\n",
    "bar_height = 0.3\n",
    "\n",
    "for i, row in grouped_isic_other_df.iterrows():\n",
    "    isic_category = row['ISIC_Category_Section']\n",
    "    value = row['GWP100_Impact_Value_kg_CO2eq']\n",
    "    plt.barh(\n",
    "        y=0,\n",
    "        width=value,\n",
    "        left=cumulative_width,\n",
    "        height=bar_height,\n",
    "        color=colors[i % len(colors)],\n",
    "        edgecolor='white',\n",
    "        linewidth=2,\n",
    "        label=isic_category\n",
    "    )\n",
    "    # Add text for segments wide enough\n",
    "    if value > 0.05:\n",
    "        plt.text(\n",
    "            x=cumulative_width + value / 2,\n",
    "            y=0,\n",
    "            s=f'{value:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=12,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    cumulative_width += value\n",
    "\n",
    "# Add total at the end\n",
    "plt.text(\n",
    "    x=cumulative_width + 0.03 * cumulative_width,\n",
    "    y=0,\n",
    "    s=f'Total: {cumulative_width:.2f}',\n",
    "    va='center',\n",
    "    ha='left',\n",
    "    color='white',\n",
    "    fontsize=13,\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.xlabel('GWP100 Impact (kg CO2eq per kg H2)', fontsize=13, color='white')\n",
    "plt.title(f'{product_system_name_simplified} - by ISIC Category', fontsize=14, color='white', pad=15)\n",
    "plt.xticks(color='white', fontsize=11)\n",
    "plt.yticks([])\n",
    "\n",
    "plt.xlim(0, cumulative_width * 1.12)\n",
    "\n",
    "plt.legend(\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    "    ncol=1,\n",
    "    fontsize=11,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01756130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified horizontal bar plot with segments in descending order for grouped_flows_other_df\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Sort the DataFrame by impact values in descending order\n",
    "grouped_flows_other_df.sort_values(by='GWP100_Impact_Value_kg_CO2eq', ascending=False, inplace=True)\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "cumulative_width = 0\n",
    "bar_height = 0.3\n",
    "\n",
    "for i, row in grouped_flows_other_df.iterrows():\n",
    "    flow = row['Flow']\n",
    "    value = float(row['GWP100_Impact_Value_kg_CO2eq'])\n",
    "    plt.barh(\n",
    "        y=0,\n",
    "        width=value,\n",
    "        left=cumulative_width,\n",
    "        height=bar_height,\n",
    "        color=colors[i % len(colors)],\n",
    "        edgecolor='white',\n",
    "        linewidth=2,\n",
    "        label=flow\n",
    "    )\n",
    "    # Add text for segments wide enough\n",
    "    if value > 0.05:\n",
    "        plt.text(\n",
    "            x=cumulative_width + value / 2,\n",
    "            y=0,\n",
    "            s=f'{value:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=12,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    cumulative_width += value\n",
    "\n",
    "# Add total at the end\n",
    "plt.text(\n",
    "    x=cumulative_width + 0.03 * cumulative_width,\n",
    "    y=0,\n",
    "    s=f'Total: {cumulative_width:.2f}',\n",
    "    va='center',\n",
    "    ha='left',\n",
    "    color='white',\n",
    "    fontsize=13,\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.xlabel('GWP100 Impact (kg CO2eq per kg H2)', fontsize=13, color='white')\n",
    "plt.title(f'{product_system_name_simplified} - by Flows', fontsize=14, color='white', pad=15)\n",
    "plt.xticks(color='white', fontsize=11)\n",
    "plt.yticks([])\n",
    "\n",
    "plt.xlim(0, cumulative_width * 1.12)\n",
    "\n",
    "plt.legend(\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    "    ncol=1,\n",
    "    fontsize=11,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
